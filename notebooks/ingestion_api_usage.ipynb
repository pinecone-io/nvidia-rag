{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650fa9f0",
   "metadata": {},
   "source": [
    "# Ingestion API Usage\n",
    "\n",
    "This notebook demonstrates how to interact with the ingestion APIs to upload and index documents for retrieval-augmented generation (RAG) applications. It showcases the different APIs needed to create a collection, upload documents to the created collection using Milvus Vector DB. It also showcases different APIs to manage uploaded documents and existing collections effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5726313-f5ab-48fb-b747-c790ebaafe48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Ensure the ingestor-server container is running before executing the notebook by [following steps in the readme](../docs/quickstart.md#start-the-containers-for-ingestion-microservices).\n",
    "- Replace `BASE_URL` with the actual server URL if the API is hosted on another system.\n",
    "- You can customize the directory path (`../data/multimodal`) with the correct location of your dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58505d5-5436-449a-b316-b943a1a57797",
   "metadata": {},
   "source": [
    "#### 1. Install Dependencies and import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78246c4e-040d-4e06-8ed3-edb88ca0c280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optional module torch not installed.\n",
      "/Users/cory/dev/pinecone-io/nvidia-rag/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"./.env_library\")\n",
    "\n",
    "%pip install -q -r requirements.txt\n",
    "import aiohttp\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"../src\") # Adjust path as needed\n",
    "from nvidia_rag.utils.vectorstore import create_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a494be7-ffee-4dfb-968f-c5300f6ba0a2",
   "metadata": {},
   "source": [
    "#### 2. Setup Base Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2807ea21-f9b8-408b-b2ee-318bef308d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPADDRESS = \"ingestor-server\" if os.environ.get(\"AI_WORKBENCH\", \"false\") == \"true\" else \"localhost\" # Replace this with the correct IP address\n",
    "INGESTOR_SERVER_PORT = \"8082\"\n",
    "BASE_URL = f\"http://{IPADDRESS}:{INGESTOR_SERVER_PORT}\"  # Replace with your server URL\n",
    "\n",
    "async def print_response(response):\n",
    "    \"\"\"Helper to print API response.\"\"\"\n",
    "    try:\n",
    "        response_json = await response.json()\n",
    "        print(json.dumps(response_json, indent=2))\n",
    "    except aiohttp.ClientResponseError:\n",
    "        print(await response.text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f85b3-767b-4e8f-82da-9d5c7069d609",
   "metadata": {},
   "source": [
    "#### 3. Health Check Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint performs a health check on the server. It returns a 200 status code if the server is operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32e53c4-909b-4b04-975f-c598f33bd797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"message\": \"Ingestion Service is up.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "async def fetch_health_status():\n",
    "    \"\"\"Fetch health status asynchronously.\"\"\"\n",
    "    url = f\"{BASE_URL}/v1/health\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            await print_response(response)\n",
    "\n",
    "# Run the async function\n",
    "await fetch_health_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850cbb2",
   "metadata": {},
   "source": [
    "#### 4. Create collection Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint is used to create a collection in the vector store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e658845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call create collection method\n",
    "create_collection(\n",
    "    vdb_endpoint=f\"{os.getenv('APP_VECTORSTORE_URL')}\",\n",
    "    collection_name=\"multimodal_data\"\n",
    ")\n",
    "\n",
    "# Only use the following if your vector store does not support native metadata management and requires a metadata schema collection.\n",
    "# from vectorstore import create_metadata_schema_collection\n",
    "# await create_metadata_schema_collection(\n",
    "#     vdb_endpoint=f\"{os.getenv('APP_VECTORSTORE_URL')}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2334abfc-5832-4e39-8793-818b5265aa1d",
   "metadata": {},
   "source": [
    "#### 4. Upload Document Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint uploads new documents to the vector store. \n",
    "1. You can specify the collection name where the documents should be stored. \n",
    "2. The collection to which the documents are being uploaded must exist in the vector database.\n",
    "3. The documents which are uploaded must not exist in the collection. If the documents already exists, to reingest existing files in the provided collection, replace `session.post(...)` with `session.patch(...)`\n",
    "4. To speed up the ingestion process, the multiple files can be passed in a single request as showcased below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8709ab2e-c1de-42d4-96b2-eb104f8bd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "FILEPATHS =  [\n",
    "    '../data/multimodal/embedded_table.pdf',\n",
    "    '../data/multimodal/functional_validation.pdf',\n",
    "    '../data/multimodal/woods_frost.pdf',\n",
    "    '../data/multimodal/multimodal_test.pdf',\n",
    "    '../data/multimodal/table_test.pdf',\n",
    "    '../data/multimodal/woods_frost.docx'\n",
    "]\n",
    "\n",
    "# [Optional]: Add filename specific custom metadata\n",
    "# Note: timestamp metadata field must be in ISO 8601 format so following operands are supported: \"==\", \"<=\",\n",
    "CUSTOM_METADATA = [\n",
    "    {\n",
    "        \"filename\": \"multimodal_test.pdf\",\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": \"2000-05-15T10:23:00\",\n",
    "            \"meta_field_1\": \"multimodal document\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"functional_validation.pdf\",\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": \"2001-05-15T10:23:00\",\n",
    "            \"meta_field_1\": \"functional validation document\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"woods_frost.pdf\",\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": \"2002-05-15T10:23:00\",\n",
    "            \"meta_field_1\": \"multimodal document\"\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d611db2-c663-4014-bd6e-fb0a279a04c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"message\": \"Ingestion started in background\",\n",
      "  \"task_id\": \"bc2bb33e-9e09-4bb1-bb4d-fdb0908a6124\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "async def upload_documents(collection_name: str = \"\"):\n",
    "\n",
    "    data = {\n",
    "        \"collection_name\": collection_name,\n",
    "        \"blocking\": False, # If True, upload is blocking; else async. Status API not needed when blocking\n",
    "        \"split_options\": {\n",
    "            \"chunk_size\": 512,\n",
    "            \"chunk_overlap\": 150\n",
    "        },\n",
    "        \"custom_metadata\": CUSTOM_METADATA,\n",
    "        \"generate_summary\": False # Set to True to optionally generate summaries for all documents after ingestion\n",
    "    }\n",
    "\n",
    "    form_data = aiohttp.FormData()\n",
    "    for file_path in FILEPATHS:\n",
    "        form_data.add_field(\"documents\", open(file_path, \"rb\"), filename=os.path.basename(file_path), content_type=\"application/pdf\")\n",
    "\n",
    "    form_data.add_field(\"data\", json.dumps(data), content_type=\"application/json\")\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.post(f\"{BASE_URL}/v1/documents\", data=form_data) as response: # Replace with session.patch for reingesting\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "await upload_documents(collection_name=\"multimodal_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554475c3-b8dc-41d9-94b9-fb833a46e2fc",
   "metadata": {},
   "source": [
    "#### 5. Get Task Status Endpoint:\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint is used to get task status of upload documents task. When task is `\"FINISHED\"`, this endpoint can be used to get status report of the upload task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c668bb85-3b77-4c43-9274-61e5037e3a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"state\": \"UNKNOWN\",\n",
      "  \"result\": {\n",
      "    \"message\": \"Unknown task state\",\n",
      "    \"total_documents\": 0,\n",
      "    \"documents\": [],\n",
      "    \"failed_documents\": [],\n",
      "    \"validation_errors\": []\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "async def get_task_status(\n",
    "    task_id: str\n",
    "):\n",
    "\n",
    "    params = {\n",
    "        \"task_id\": task_id,\n",
    "    }\n",
    "\n",
    "    HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(f\"{BASE_URL}/v1/status\", params=params, headers=HEADERS) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            return 500, {\"error\": str(e)}\n",
    "\n",
    "await get_task_status(task_id=[\"*****************************\"]) # Please enter the task_id obtained from upload documents API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191cd7f-02d1-45c6-90a7-f3ca86c4046a",
   "metadata": {},
   "source": [
    "#### 6. Get Documents Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint retrieves a list of documents ingested into the vector store for a specified collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a250bcc6-2137-40d2-95ff-6202faff4fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"message\": \"Document listing failed due to error pinecone vector database is not supported.\",\n",
      "  \"total_documents\": 0,\n",
      "  \"documents\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "async def fetch_documents(collection_name: str = \"\"):\n",
    "    url = f\"{BASE_URL}/v1/documents\"\n",
    "    params = {\"collection_name\": collection_name}\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(url, params=params) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "await fetch_documents(collection_name=\"multimodal_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b9e3c-2092-4d6b-9ff7-64d33730337b",
   "metadata": {},
   "source": [
    "#### 7. Delete Documents Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint deletes specified documents from the vector store. The documents are identified by its filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5ebcd-f741-491c-a797-ee4fd15c9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "async def delete_documents(collection_name: str = \"\", file_names: List[str] = []):\n",
    "    url = f\"{BASE_URL}/v1/documents\"\n",
    "    params = {\"collection_name\": collection_name}\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.delete(url, params=params, json=file_names) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "await delete_documents(collection_name=\"multimodal_data\", file_names=[\"embedded_table.pdf\", \"table_test.pdf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec9bfd5-b943-4eed-874b-9067fdfe06ca",
   "metadata": {},
   "source": [
    "#### 8. Get Collections Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint retrieves a list of all collection names available on the server. Collections are used to organize documents in the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6114bb1-f0f0-4444-859f-d4dc66fa9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_collections():\n",
    "    url = f\"{BASE_URL}/v1/collections\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(url) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "await fetch_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b97e846",
   "metadata": {},
   "source": [
    "#### 9. Delete Collections Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint deletes list of provided collection names available on the specified vector database server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8489ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "async def delete_collections(collection_names: List[str] = \"\"):\n",
    "    url = f\"{BASE_URL}/v1/collections\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.delete(url, json=collection_names) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "await delete_collections(collection_names=[\"multimodal_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c212878-6925-4497-a6a5-89ecd5911cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
